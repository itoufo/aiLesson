# 第3章：AI倫理と安全性

## 学習目標

この章を終えると、以下のことができるようになります：

- AI活用における主要な倫理的課題を説明できる
- 著作権・個人情報保護の基本ルールを理解できる
- AIのバイアスとその影響を認識できる
- 安全なAI活用のための具体的な対策を実践できる

---

## 3.1 なぜAI倫理が重要か

### 3.1.1 AI活用の両面性

![AIの両面性](/docs/images/01_入門/03_ai_duality.jpeg)

### 3.1.2 HAIIAの倫理原則

一般社団法人健全AI教育協会（HAIIA）が掲げる原則：

| 原則 | 内容 |
|------|------|
| **人間中心** | AIは人間を豊かにする道具として位置づける |
| **倫理優先** | 技術的可能性より倫理的妥当性を優先 |
| **公平性** | 特定の集団に不利益をもたらさない |
| **透明性** | AI活用の事実と限界を明示する |
| **責任性** | 人間がAIの活用に責任を持つ |

---

## 3.2 著作権とAI

### 3.2.1 生成AIと著作権の基本

![著作権に関する2つの視点](/docs/images/01_入門/03_copyright.jpeg)

### 3.2.2 AI生成物の著作権

| 状況 | 著作権の扱い |
|------|-------------|
| AIのみで生成（人間の創作的関与なし） | 著作権なし |
| 人間がプロンプトで詳細に指示 | ケースバイケース（争いあり） |
| 人間がAI出力を大幅に編集・加工 | 編集部分に著作権発生の可能性 |
| AIを道具として使い人間が創作 | 人間に著作権 |

### 3.2.3 安全な活用のためのガイドライン

```
【入力時のチェックリスト】
□ 他人の著作物をそのままコピー＆ペーストしていないか
□ 入力する情報に機密情報が含まれていないか
□ 第三者の個人情報を入力していないか
□ 利用規約で禁止されている用途ではないか

【出力時のチェックリスト】
□ 出力が既存の著作物に酷似していないか確認したか
□ 重要な出力は人間が確認・編集しているか
□ AI生成であることを必要に応じて明示しているか
□ 商用利用の場合、サービスの利用規約を確認したか
```

---

## 3.3 個人情報保護

### 3.3.1 AIと個人情報のリスク

![個人情報に関するリスク](/docs/images/01_入門/03_privacy_risk.jpeg)

### 3.3.2 個人情報保護のための対策

| 対策 | 具体的な方法 |
|------|-------------|
| **匿名化** | 氏名を「Aさん」「Bさん」に置換 |
| **マスキング** | 電話番号を「xxx-xxxx-xxxx」に置換 |
| **抽象化** | 具体的な住所を「関東地方」に置換 |
| **削除** | 不要な個人情報は入力前に削除 |
| **設定確認** | 学習オプトアウト設定の確認 |

### 3.3.3 サービスごとのデータ取り扱い確認

```
【確認すべき項目】
1. 入力データは学習に使用されるか？
2. オプトアウト（学習拒否）は可能か？
3. データの保存期間は？
4. 第三者への提供はあるか？
5. セキュリティ対策は十分か？

【主要サービスの例】
・ChatGPT: 設定でオプトアウト可能、API利用は原則学習されない
・Claude: API利用は原則学習されない
・企業向けプラン: 多くのサービスで学習対象外
```

---

## 3.4 AIバイアス

### 3.4.1 バイアスとは

**バイアス（偏見・偏り）** とは、AIが特定の集団に対して不公平な判断や出力をする傾向です。

![AIバイアスの発生メカニズム](/docs/images/01_入門/03_bias.jpeg)

### 3.4.2 バイアスの種類と例

| バイアスの種類 | 説明 | 例 |
|----------------|------|-----|
| **性別バイアス** | 性別による偏り | 「看護師」で女性画像ばかり生成 |
| **人種バイアス** | 人種・民族による偏り | 顔認識の精度が人種で異なる |
| **年齢バイアス** | 年齢による偏り | 高齢者に不利な評価 |
| **文化バイアス** | 文化・地域による偏り | 欧米中心の価値観での回答 |
| **確証バイアス** | 既存の見方を強化 | ユーザーの意見に迎合 |

### 3.4.3 バイアスへの対処

```
【AIを使う側の対策】

1. バイアスの存在を認識する
   ・AIの出力は中立ではないことを理解

2. 多角的な視点で確認
   ・異なる表現で同じ質問をしてみる
   ・複数のAIサービスで比較する

3. 重要な判断は人間が行う
   ・採用、評価、融資などはAIを参考にとどめる

4. フィードバックを行う
   ・偏った出力を報告する
```

---

## 3.5 情報セキュリティ

### 3.5.1 AI活用における情報漏洩リスク

![情報漏洩の経路](/docs/images/01_入門/03_data_leak.jpeg)

### 3.5.2 機密情報の分類と取り扱い

| 機密レベル | 例 | AI入力 |
|------------|-----|--------|
| **極秘** | 未発表の決算情報、M&A計画 | 禁止 |
| **秘密** | 顧客リスト、内部戦略文書 | 原則禁止 |
| **社外秘** | 社内規程、業務マニュアル | 匿名化して限定的に |
| **公開** | 公開済みプレスリリース | 可能 |

### 3.5.3 セキュアなAI活用環境

![企業向けAI活用の推奨構成](/docs/images/01_入門/03_enterprise_ai.jpeg)

---

## 3.6 生成AIの安全利用ガイドライン

### 3.6.1 業務利用の基本ルール

![生成AI業務利用10のルール](/docs/images/01_入門/03_10rules.jpeg)

### 3.6.2 リスク別対応表

| リスク | 発生時の対応 |
|--------|-------------|
| **誤情報の発信** | 速やかに訂正、影響範囲の確認 |
| **個人情報の入力** | 上長・情報管理部門に報告、削除依頼 |
| **著作権侵害の疑い** | 使用停止、法務部門に相談 |
| **差別的出力の使用** | 使用停止、関係者への謝罪検討 |
| **機密情報の入力** | 即座に報告、リスク評価 |

---

## 3.7 責任あるAI活用

### 3.7.1 AIガバナンスの考え方

![責任あるAI活用の枠組み](/docs/images/01_入門/03_governance.jpeg)

### 3.7.2 個人としての責任

| 場面 | 責任ある行動 |
|------|-------------|
| **入力時** | 不適切な情報を入力しない |
| **出力時** | 内容を確認し、必要な修正を行う |
| **共有時** | AI生成であることを適切に伝える |
| **問題発生時** | 速やかに報告し、対処に協力する |

---

## 確認クイズ

### Q1. 著作権
AI生成物の著作権について正しいものはどれですか？

- [ ] A) AIが生成したものにはすべて著作権が発生する
- [ ] B) AIが生成したものには一切著作権が発生しない
- [ ] C) 人間の創作的関与の度合いによって判断が分かれる
- [ ] D) AIサービス提供会社に著作権が帰属する

### Q2. 個人情報
生成AIに個人情報を入力する際の対策として不適切なものは？

- [ ] A) 氏名を匿名化してから入力する
- [ ] B) 企業向けプラン（学習に使われない）を利用する
- [ ] C) 重要でない個人情報ならそのまま入力して良い
- [ ] D) 入力前に個人情報を削除する

### Q3. バイアス
AIバイアスへの対処として適切なものは？

- [ ] A) AIの出力は常に中立なので対処不要
- [ ] B) バイアスの存在を認識し、重要な判断は人間が行う
- [ ] C) バイアスは技術的に解決済みなので心配不要
- [ ] D) バイアスを避けるためAIの利用を中止する

---

## 章末まとめ

### 本章のポイント

1. **AI倫理**は「人間中心」「公平性」「透明性」「責任性」が基本
2. **著作権**は入力・出力の両面で注意が必要
3. **個人情報**は匿名化・マスキングで保護する
4. **バイアス**の存在を認識し、重要な判断は人間が行う
5. **責任**は最終的に人間が負う

### 次章への準備

次章「プロンプト基礎」では、AIに効果的な指示を出す方法を学びます。

---

## 参考資料

- 文化庁「AIと著作権に関する考え方について」
- 個人情報保護委員会「生成AIサービスの利用に関する注意喚起」
- 総務省「AI利活用ガイドライン」
- Microsoft「責任あるAI原則」

---

©健全AI教育協会
